# ğŸ§± Pix2Vox-Inspired 3D Reconstruction Model

This project implements a custom **Pix2Vox-like 3D reconstruction pipeline** using **PyTorch**. It reconstructs 3D voxel grids from multi-view 2D images using a modular design (Encoder â†’ Decoder â†’ Merger â†’ Refiner), optimized for ShapeNet-style datasets. It supports AMP training and includes a Jupyter-based inference notebook.

---

## ğŸš€ Features

### ğŸ§  Modular Architecture
- Encoder â†’ Decoder â†’ Merger â†’ Refiner pipeline
- Multi-view voxel reconstruction (default: 32Ã—32Ã—32)
- AMP (`torch.cuda.amp`) support for fast mixed-precision training

### ğŸ“¦ Dataset Handling
- Custom `ShapeNetDataset` class in `utils/DataSetLoader.py`
- Reads `.binvox` voxel files and multi-view 2D images
- Dataset must be placed inside the root directory as `DataSet/`

### ğŸ““ Jupyter Inference
- `inference_pipeline.ipynb` provided for running predictions
- Visualizes reconstructed voxel grids in 3D

### ğŸ“ˆ Training Utilities
- Real-time progress via `tqdm`
- TensorBoard logging
- Auto-saves checkpoints inside `core/checkpoints/` folder

---

## ğŸ› ï¸ Tech Stack

- **Framework:** PyTorch  
- **Visualization:** Matplotlib (3D voxels)  
- **AMP Training:** `torch.cuda.amp`  
- **UI (Inference):** Jupyter Notebook  

---

## ğŸ“‚ Project Structure

```
Pix2Vox/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ train.py              # training script (edit dataset paths here)
â”‚   â””â”€â”€ checkpoints/          # gets created automatically
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ encoder.py
â”‚   â”œâ”€â”€ decoder.py
â”‚   â”œâ”€â”€ merger.py
â”‚   â””â”€â”€ refiner.py
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ DataSetLoader.py
â”œâ”€â”€ inference_pipeline.ipynb  # notebook for testing predictions
â””â”€â”€ DataSet/                  # place your dataset here
```

---

## âš™ï¸ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/Slayer9966/Pix2Vox.git
cd Pix2Vox
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Add Dataset

Place your ShapeNet-style dataset as follows:

```
Pix2Vox/
â””â”€â”€ DataSet/
    â”œâ”€â”€ ShapeNetVox32_32/
    â””â”€â”€ ShapeNetRendering/
```

Edit the paths manually inside:

```bash
core/train.py
```

---

## ğŸ§  Pretrained Weights

Download pretrained weights from [Google Drive](https://drive.google.com/file/d/1U1Hr8hPXtdea3P1hwpm2UL_A7efxze_T/view?usp=sharing) and place the `.pth` file in main directory and change the path in inference_pipeline.ipynb:

```bash
model.pth
```



---

## â–¶ï¸ Training the Model

```bash
python core/train.py
```

> The `core/checkpoints/` folder will be created automatically when training starts.

---

## ğŸ““ Running Inference

Use the provided notebook and place the images inside the data folder in the main directory so it performs the inference on it:

```bash
inference_pipeline.ipynb
```

- You can set custom view images and run forward passes to visualize voxel outputs.
- Make sure the weights are loaded from the correct checkpoint path.

---

## ğŸ“Œ Notes

- Training requires CUDA-enabled GPU (recommended)
- Dataset format: `.binvox` voxel + 13-view rendered images
- Logs are saved using `tensorboard`
- Model reconstructs 3D voxel grids from 2D multi-view images

---

## ğŸ“œ License

Licensed under the **[MIT License](https://github.com/Slayer9966/2D-TO-3D-multi-view/blob/main/LICENSE)** â€” free to use, modify, and distribute.

---

## ğŸ™‹â€â™‚ï¸ Author

**Syed Muhammad Faizan Ali**  
ğŸ“ Islamabad, Pakistan  
ğŸ“§ faizandev666@gmail.com  
ğŸ”— [GitHub](https://github.com/Slayer9966) | [LinkedIn](https://www.linkedin.com/in/faizan-ali-7b4275297/)
ğŸ“¢ If you find this project helpful or use it in your work, please consider giving it a â­ or letting me know via email or GitHub issues!
